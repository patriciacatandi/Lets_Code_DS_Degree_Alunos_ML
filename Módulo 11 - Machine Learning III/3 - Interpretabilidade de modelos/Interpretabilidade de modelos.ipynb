{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretabilidade de modelos\n",
    "\n",
    "Nas próximas duas aulas vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Interpretabilidade de modelos\n",
    "- 2) Modelos naturalmente interpretáveis\n",
    "- 3) LIME\n",
    "- 4) SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T22:22:59.730275Z",
     "start_time": "2022-03-16T22:22:38.944478Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T22:22:59.746249Z",
     "start_time": "2022-03-16T22:22:59.733257Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "def metricas_classificacao(estimator, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # ============================================\n",
    "\n",
    "    print(\"\\nMétricas de avaliação de treino:\")\n",
    "\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(y_train, y_pred_train)\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "    # ============================================\n",
    "\n",
    "    print(\"\\nMétricas de avaliação de teste:\")\n",
    "\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred_test)\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "## 1) Interpretabilidade de modelos\n",
    "\n",
    "Nesta altura, já entendemos bem **o que** é um modelo, e como podemos construir modelos dos mais variados tipos.\n",
    "\n",
    "Muitas vezes, no entanto, é de interesse que os modelos criados sejam **interpretáveis**, isto é, que seja possível **analisarmos porque/como o target $\\hat{y}$ foi produzido pelo modelo**.\n",
    "\n",
    "A necessidade ou não de interpretabilidade de modelos depende, muitas vezes, do problema de negócio específico. Pode haver certos problemas em que o objetivo é que tenhamos o modelo **com a melhor performance possível**, sem que haja necessidade de interpretarmos **o que** o modelo está fazendo. Se este for o caso, somos completamente livres para utilizar qualquer técnica que desejarmos, visando sempre aumentar a performance do modelo.\n",
    "\n",
    "Em outros casos, no entanto, performance máxima não é o único objetivo: é necessário que os modelos produzidos também sejam interpretáveis, por diversos motivos, a citar alguns:\n",
    "\n",
    "- Necessidade de extração de insights estratégicos a partir das estruturas aprendidas;\n",
    "- Obrigação regulatória de interpretabilidade;\n",
    "- Necessidade de adequação à regras de negócio particulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, se interpretabiliade for uma questão importante, é importante que guiemos a construção de nossos modelos com este objetivo em mente. Para isso, há, essencialmente, duas abordagens possíveis:\n",
    "\n",
    "> **Criar modelos naturalmente interpretáveis**: há modelos (que já conhecemos!), que são facilmente interpretáveis, devido à estrutura particular da hipótese. Assim, se interpretabilidade for algo importante, escolher estas hipóteses pode ser uma boa alternativa. \n",
    "<br><br>\n",
    "No entanto, um ponto importantíssimo a ser considerado é que **há alguns procedimentos de pré-processamento** que podem obscurecer esta interpretabilidade natural (por exemplo: scalers, PCA, etc.). \n",
    "<br><br>\n",
    "Portanto, se interpretabilidade de fato for uma questão, é muito importante que atenção seja tomada **até mesmo no pré-processamento** dos dados, mesmo que isso possa comprometer parte da performance do modelo;\n",
    "\n",
    "> **Aplicar alguma técnica de explicabilidade de modelos**: se a busca por interpretabilidade acabar comprometendo muito a perfromance, é possível que sigamos com modelos que não sejam naturalmente interpretáveis, mas que possam ser interpretados por técnicas específicas que buscam interpretabilidade. Vamos estudar estas técnicas hoje!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de mergulharmos neste assunto, um último comentário: a questão de interpretabilidade de modelos de ML é de extremo interesse pela comunidade científica, e cada vez mais tem ganhado espaço no mundo corporativo. De maneira mais geral, esta área é conhecida como [Explainable AI](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence), e há grande esforço na direção de tornar AI uma área interpretável, o que leva a discussões bem fundamentais sobre estas tecnologias. Para quem se interessar, sugiro algumas leituras: [aqui, da IBM](https://www.ibm.com/watson/explainable-ai); [e aqui, do Google](https://cloud.google.com/explainable-ai).\n",
    "\n",
    "E para quem realmente quiser mergulhar neste assunto, sugiro [este livro!](https://christophm.github.io/interpretable-ml-book/)\n",
    "\n",
    "Agora, vamos detalhar um pouco mais as duas abordagens descritas acima!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Modelos naturalmente interpretáveis\n",
    "\n",
    "Conforme discutimos acima, há modelos que são naturalmente explicáveis. Vamos discutir alguns deles:\n",
    "\n",
    "____________\n",
    "\n",
    "### Regressão Linear\n",
    "\n",
    "O primeiro modelo que construímos no curso, foi um modelo de regressão linear para o preço de casas, com base em uma única variável:\n",
    "\n",
    "> O nosso modelo final é dado por:\n",
    "<br><br>\n",
    "$$ y = f_H(x) =  1562.01 + 118.61\\text{GrLiveArea}$$\n",
    "<br><br>\n",
    "Isto quer dizer que:\n",
    "<br><br>\n",
    "Aumentando a variável \"GrLiveArea\" em uma unidade faz com que o preço seja aumentado em USD 118.6!\n",
    "<br><br>\n",
    "O preço mínimo a ser pago, independente da área construída, é de 1562.01!\n",
    "\n",
    "Mas mesmo modelos de regressão linear múltipla são interpretáveis! A hipótese é dada por:\n",
    "\n",
    "$$ y = f_H(\\vec{x}) = b_0 + \\sum_{i=1}^n b_i X_i = b_0 + b_1 X_1 + b_2 X_2 + \\cdots + b_n X_n $$\n",
    "\n",
    "A interpretabilidade também é direta:\n",
    "\n",
    "> Aumentando uma unidade da feature $X_i$, temos que o preço aumenta/diminui em $b_i$ unidades (a depender do sinal do coeficiente);\n",
    "<br><br>\n",
    "O preço fixo sempre é $b_0$.\n",
    "\n",
    "Note, portanto, que simplesmente ao olharmos para os parâmetros da hipótese (`.coef_` e `.intercept_`), temos informações concretas e claríssimas sobre o modo como cada feature é utilizada para, conjuntamente, predizer o target. Esse é o mais simples exemplo de interpretabilidade!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observação**: também podemos olhar para o \"tamanho\" dos coeficientes para entender quais features são \"mais importantes\": coeficientes maiores (em valor absoluto) estão associados a \"maior peso\" na determinação do target. \n",
    "\n",
    "No entanto, a escala das features interfere nesta análise! Features com escala maior tendem a proporcionar coeficientes menores, e vice-versa. Por isso, se o objetivo é inspecionar importância de features na regressão linear, é importante que os dados sejam previamente escalados! [Este post](https://towardsdatascience.com/feature-importance-in-linear-models-four-often-neglected-but-crucial-pitfalls-e5c513e45b18) discute este ponto brevemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "\n",
    "### Árvores\n",
    "\n",
    "Árvores são modelos naturalmente interpretáveis também: podemos inspecionar **o caminho que cada observação percorre do nó raiz até a folha** para entender exatamente qual foi o critério para a decisão, nó a nó!\n",
    "\n",
    "Podemos inspecionar este caminho olhando para uma árvore plotada, ou então utilizando o método [decision_path!](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.decision_path) Vamos ver um exemplo rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:29:15.314850Z",
     "start_time": "2022-03-14T23:29:15.278851Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:29:56.551105Z",
     "start_time": "2022-03-14T23:29:56.534114Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:30:36.572437Z",
     "start_time": "2022-03-14T23:30:35.834931Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instancia e fita o DecisionTree\n",
    "tree =\n",
    "\n",
    "# metricas_classificacao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos descobrir a profundidade da árvore com o método `.get_depth()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:31:29.254786Z",
     "start_time": "2022-03-14T23:31:29.243794Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos plotar a àrvore com o plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "plot_tree(tree, feature_names=tree.feature_names_in_, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o método `decision_path()` é possível visualizar o caminho percorrido por cada amostra. A saída desse método é uma matriz esparça e leva em consideração que as posições seguem o padrão de busca do algoritmo em profundidade-primeiro (Depth-First Search - DFS) da teoria dos grafos:\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/5/5d/Depth-first-tree.png text=\"https://pt.wikipedia.org/wiki/Busca_em_profundidade\" width=400 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:41:39.323767Z",
     "start_time": "2022-03-14T23:41:39.314775Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos olhar quais eram os valores das features do `X_test.iloc[[0]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:42:00.144360Z",
     "start_time": "2022-03-14T23:42:00.121353Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos comparar com o caminho de decisão nessa mesma posição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:42:10.996974Z",
     "start_time": "2022-03-14T23:42:10.978007Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar essa posição no y_test para ver qual foi a predição do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:43:29.520083Z",
     "start_time": "2022-03-14T23:43:29.497093Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos realizar esse mesmo processo com a amostra que está no índex 21. Primeiro olhamos os valores da feature no X_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:43:56.231455Z",
     "start_time": "2022-03-14T23:43:56.211466Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora verificamos qual foi o caminho da decisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:44:08.851084Z",
     "start_time": "2022-03-14T23:44:08.833066Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E por fim olhamos o y_test para saber a predição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:44:56.127828Z",
     "start_time": "2022-03-14T23:44:56.114833Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber mais, como se aproveitar dessas estruturas, [clique aqui!](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptando o código da página acima, podemos construir uma função para interpretar a árvore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:06:31.854868Z",
     "start_time": "2022-03-15T00:06:31.825885Z"
    }
   },
   "outputs": [],
   "source": [
    "def interpreta_arvore(tree, X_test, idx):\n",
    "    \n",
    "    node_indicator = tree.decision_path(X_test)\n",
    "    leaf_id = tree.apply(X_test)\n",
    "    feature = tree.tree_.feature\n",
    "    threshold = tree.tree_.threshold\n",
    "\n",
    "    node_index = node_indicator.indices[node_indicator.indptr[idx] : node_indicator.indptr[idx + 1]]\n",
    "    \n",
    "    print(f\"{idx+1}a observação de teste:\")\n",
    "    display(X_test.iloc[[idx]])\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(\"Regras utilizada em cada nó percorrido da árvore:\\n\")\n",
    "\n",
    "    feature_names = tree.feature_names_in_\n",
    "    \n",
    "    for node_id in node_index:\n",
    "\n",
    "        # continue to the next node if it is a leaf node\n",
    "        if leaf_id[idx] == node_id:\n",
    "            continue\n",
    "\n",
    "        # check if value of the split feature for sample 0 is below threshold\n",
    "        if X_test.iloc[idx][feature[node_id]] <= threshold[node_id]:\n",
    "            threshold_sign = \"<=\"\n",
    "        else:\n",
    "            threshold_sign = \">\"\n",
    "        \n",
    "        print(\"Nó de decisão {node} : ({feature_name} = {value}) \"\n",
    "              \"{inequality} {threshold:.2f})\".format(node=node_id,\n",
    "                                                     feature_name=feature_names[feature[node_id]],\n",
    "                                                     value=X_test.iloc[idx][feature[node_id]],\n",
    "                                                     inequality=threshold_sign,\n",
    "                                                     threshold=threshold[node_id]))\n",
    "        \n",
    "    y_pred = tree.predict(X_test)[idx]\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Predição na folha: y = {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:07:45.405452Z",
     "start_time": "2022-03-15T00:07:44.516391Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    interpreta_arvore(tree, X_test, i)\n",
    "    \n",
    "    print(\"\\n\", \"#\"*80, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "\n",
    "### KNN\n",
    "\n",
    "Modelos KNN também são interpretáveis, em certa medida, pois podemos **olhar para os vizinhos que foram levados em conta pra tomar a decisão**, e com isso, podemos comparar estes vizinhos com a observação de teste, e, assim, interpretar a decisão!\n",
    "\n",
    "Fazemos isso com o método [kneighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors). Vamos ver um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:11:02.074466Z",
     "start_time": "2022-03-15T00:11:02.058479Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:11:49.950790Z",
     "start_time": "2022-03-15T00:11:49.121165Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instanciar e fitar o KNN\n",
    "\n",
    "# Metricas_classificacao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o método `.kneighbors()`, vamos obter qual a distância e quem são os k vizinhos mais próximos na classificação do X_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:13:53.563451Z",
     "start_time": "2022-03-15T00:13:53.546460Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_k, idcs_k = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos olhar, por exemplo, apenas para a primeira observação do X_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:14:26.154065Z",
     "start_time": "2022-03-15T00:14:26.137072Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a primeira saída do `kneigbors` podemos ver qual a distância dos vizinhos mais próximos selecionando o índex 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:14:16.073384Z",
     "start_time": "2022-03-15T00:14:16.057365Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a segunda saída do `kneigbors` podemos ver quais os índices dos k vizinhos mais próximos selecionando o índex 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:15:37.034744Z",
     "start_time": "2022-03-15T00:15:37.017754Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar os índices para inspecionar quais foram as observações utilizadas do X_train na classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:16:52.100533Z",
     "start_time": "2022-03-15T00:16:52.081546Z"
    }
   },
   "outputs": [],
   "source": [
    "# cuidado: temos que usar o iloc, pq os idcs_k são as POSIÇÕES ordinais das observações,\n",
    "# não os indices do pandas!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver o `.describe()` das amostras que tem esses índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:18:37.239048Z",
     "start_time": "2022-03-15T00:18:37.201051Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os índices e o y_train podemos ver quais eram as classes desses k vizinhos mais próximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:19:12.725369Z",
     "start_time": "2022-03-15T00:19:12.704381Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz sentido, pois se dermos um predict nesse ponto temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:20:12.957089Z",
     "start_time": "2022-03-15T00:20:12.936100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:20:24.955353Z",
     "start_time": "2022-03-15T00:20:24.945359Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpreta_knn(knn, X_train, y_train, X_test, idx):\n",
    "    \n",
    "    print(f\"{idx+1}a observação de teste:\")\n",
    "    display(X_test.iloc[[idx]])\n",
    "    \n",
    "    dist_k, indices_k = knn.kneighbors(X_test)\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Número de vizinhos utilizados na classificação: {knn.n_neighbors}\\n\")\n",
    "    \n",
    "    print(f\"Distância entre observação de teste e cada vizinho:\\n{np.round(dist_k[idx], 3)}\\n\")\n",
    "    \n",
    "    print(f\"Vizinhos utilizados, e respectivo target:\")\n",
    "    display(pd.concat([X_train.iloc[indices_k[idx]], y_train.iloc[indices_k[idx]]], axis=1))\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"Probas de cada classe:\")\n",
    "    display(pd.DataFrame({\"probas\":knn.predict_proba(X_test)[idx]}, index=knn.classes_).T)\n",
    "    \n",
    "    print(f\"Classe final predita: {knn.predict(X_test)[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T00:26:07.738187Z",
     "start_time": "2022-03-15T00:26:05.703782Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    interpreta_knn(knn, X_train, y_train, \n",
    "                   X_test, idx=i)\n",
    "    \n",
    "    print(\"\\n\",\"#\"*80, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "O que fazemos no caso em que não é praticável utilizarmos alguns dos modelos mais simples e interpretáveis acima?\n",
    "\n",
    "Nestes casos, o que vamos querer fazer é **treinar um modelo simples $g$** que seja capaz de **explicar um modelo complexo $f$**. Diremos então que $g$ é o **modelo explicativo** de $f$!\n",
    "\n",
    "Veremos como fazer isso agora!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) LIME\n",
    "\n",
    "O LIME (**L**ocal **I**nterpretable **M**odel-agnostic **E**xplanations) é uma técnica que nos permite gerar modelos explicativos $g$ que são treinados **localmente** com o objetivo de explicar um modelo complexo $f$!\n",
    "\n",
    "Considere o classificador à esquerda, que é o modelo original ($f$). Note a fronteira de decisão não-linear, que é um indicativo de dificuldade de explicabilidade. Caso queiramos explicar este modelo globalmente, teremos dificuldades, justo? (De fato, fronteiras de decisão não-lineares são dificilmente explicáveis!)\n",
    "\n",
    "Por outro lado, **localmente**, em regiões próximas à fronteira de decisão, é possível **aproximarmos $f$ pelo modelo simples $g$, que é linear**. \n",
    "\n",
    "Com isso, **localmente**, fica fácil de explicar a decisão, com o modelo representado à direita!\n",
    "\n",
    "<img src=https://deepandshallowml.files.wordpress.com/2019/11/lime_intuition_final.png width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos lineares locais treinados pelo LIME também são conhecidos como surrogate models e seu treinamento funciona da seguinte maneira:\n",
    "\n",
    "- Um novo dataset de observações artificiais é criado (dados permutados), com base na distribuição das features na redondeza da observação a ser explicada;\n",
    "\n",
    "- A distância entre estas observações e as observações reais são calculadas;\n",
    "\n",
    "- O modelo é utilizado para predizer o `predict_proba` para estas novas observações;\n",
    "\n",
    "- Escolhe-se as `m` features mais importantes, de acordo com os dados permutados;\n",
    "\n",
    "- Um modelo linear é treinado com as `m` features, ponderando a similaridade entre samples e a observação a ser explicada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O artigo original do LIME está disponível [aqui](https://arxiv.org/pdf/1602.04938.pdf) -- e ele é (talvez surpreendentemente) simples de ler!\n",
    "\n",
    "E [neste post](https://towardsdatascience.com/decrypting-your-machine-learning-model-using-lime-5adc035109b5) há mais detalhes sobre o LIME e seu funcionamento!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, vamos ver, na prática, como aplicar o LIME!\n",
    "\n",
    "Pra isso, existe a biblioteca [LIME](https://github.com/marcotcr/lime). Para instala-la:\n",
    "\n",
    "`!pip install lime`\n",
    "\n",
    "Vamos vê-la em ação!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir um modelo bem mais complexo, para que faça sentido aplicarmos técnicas de explicabilidade!\n",
    "\n",
    "Vamos utilizar o dataset do German Credit Data pra isso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The link to the original dataset can be found below.\n",
    "\n",
    "Attribute Information:\n",
    "- Age (numeric)\n",
    "- Sex (text: male, female)\n",
    "- Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)\n",
    "- Housing (text: own, rent, or free)\n",
    "- Saving accounts (text - little, moderate, quite rich, rich)\n",
    "- Checking account (text, Conta corrente - little, moderate, nan, rich)\n",
    "- Credit amount (numeric, in Deutsch Mark)\n",
    "- Duration (numeric, Duration of the loan in month)\n",
    "- Purpose (text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/bank-full.csv\") \n",
    "df = pd.read_csv(\"../data/german_credit_data.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Saving accounts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Saving accounts'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Separar feature e target\n",
    "# y = df['Target'].copy()\n",
    "# X = df.drop(['Target', 'duration'], axis=1).copy()\n",
    "\n",
    "# Vou dropar os nans no 'Saving accounts'\n",
    "df = df.dropna(subset=['Saving accounts'])\n",
    "\n",
    "y = df['Risk'].copy()\n",
    "X = df.drop(['Risk', 'Unnamed: 0'], axis=1).copy()\n",
    "\n",
    "y = np.where(y=='good', 0, 1)\n",
    "\n",
    "X = X[['Age', 'Saving accounts', 'Credit amount', 'Duration', 'Sex']].copy()\n",
    "\n",
    "X = pd.get_dummies(X, columns=['Saving accounts', 'Sex'], drop_first=False)\n",
    "\n",
    "#### particionar dados\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_breast_cancer\n",
    "# X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T22:25:01.745148Z",
     "start_time": "2022-03-16T22:24:59.825676Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "\n",
    "metricas_classificacao(gb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No [LIME](https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular) precisamos passar os valores do X_train como um array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T22:32:19.338959Z",
     "start_time": "2022-03-16T22:32:19.289982Z"
    }
   },
   "outputs": [],
   "source": [
    "from lime import lime_tabular\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                              mode=\"classification\",\n",
    "                                              feature_names=gb.feature_names_in_,\n",
    "                                              class_names=gb.classes_,\n",
    "                                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T22:39:40.940685Z",
     "start_time": "2022-03-16T22:39:40.884675Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T22:43:41.720260Z",
     "start_time": "2022-03-16T22:43:21.507096Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(X_test.iloc[0],\n",
    "                                         gb.predict_proba,\n",
    "                                         num_features=gb.n_features_in_)\n",
    "\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima, visualizamos o resultado do explainer!\n",
    "\n",
    "O plot no centro é a principal informação para a interpretabilidade: ele exibe o valor dos coeficientes do modelo linear treinado localmente.\n",
    "\n",
    "Importante: para o treinamento do modelo linear, as features numéricas são discretizadas em bins, cujos intervalos são indicados no plot.\n",
    "\n",
    "As features são exibidas em ordem de importância, e é assim que somos capazes de descrever quais foram as features mais importantes na tomada de decisão, observação a observação!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudando a observação a ser explicada: a interpretação muda!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T22:56:28.165357Z",
     "start_time": "2022-03-16T22:56:07.487551Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(X_test.iloc[7],\n",
    "                                         gb.predict_proba,\n",
    "                                         num_features=gb.n_features_in_)\n",
    "\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo do que fizemos:\n",
    "\n",
    "Pegamos um modelo complexo, que aprendeu padrões não lineares nos dados, e o dividimos em vários modelos lineares que descrevem pontos de dados individuais através de coeficientes $ϕ$. Lembrando que esses coeficientes de explicação $ϕ$ não são a saída do modelo, mas sim o que estamos usando para interpretar o modelo e eles serão diferentes para cada ponto analisado. Ao agregar todos esses modelos simples e individuais, podemos entender como o modelo complexo se comporta em todos os pontos.\n",
    "\n",
    "Assim, em vez de tentar explicar todo o modelo complexo, tentamos explicar como o modelo complexo se comportou para um ponto de dados usando um modelo de explicação linear o qual chamamos de $g$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) SHAP\n",
    "\n",
    "Por fim, vamos dar uma olhada no SHAP (**SH**apley **A**dditive ex**P**lanation), um outro método muito utilizado para interpretabilidade.\n",
    "\n",
    "<img src=https://shap.readthedocs.io/en/latest/_images/shap_header.png width=700 />\n",
    "\n",
    "o SHAP é um método baseado em um conceito de [teoria dos jogos](https://pt.wikipedia.org/wiki/Teoria_dos_jogos) conhecido como [Shapley values](https://christophm.github.io/interpretable-ml-book/shapley.html).\n",
    "\n",
    "A ideia geral do método é encontrar **a importância das features para a predição** de modo bem explícito: para encontrar a importância de uma feature $x_i$, temos que:\n",
    "\n",
    "- Treinar o modelo $f$ com todos os **subconjuntos possíveis** de features, **incluindo $x_i$**;\n",
    "- Depois treinar o modelo $f$ com os mesmos subconjuntos, mas **excluindo $x_i$**.\n",
    "- Depois, medimos a diferença entre os outputs de cada par de modelos.\n",
    "\n",
    "Com a diferença entre os outputs, nós conseguimos medir **o impacto** da remoção daquela feature no output. Tomando uma espécie de **média** deste impacto dentre todos os subconjuntos, conseguimos ter a importância geral de $x_i$!\n",
    "\n",
    "Obs.: o operacional do método é similar ao RFE, com a diferença de que aqui consideramos **todos** os subconjuntos com e sem a feature $x_i$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de subconjuntos:\n",
    "\n",
    "Considere que temos as features $\\vec{x} = (x_1, x_2, x_3, x_4)$, e que queremos estimar o impacto da feature $x_1$. \n",
    "\n",
    "Os subconjuntos possíveis **que incluem** $x_1$ são:\n",
    "\n",
    "$ \\{x_1\\}$\n",
    "\n",
    "$ \\{x_1, x_2\\}$\n",
    "\n",
    "$ \\{x_1, x_3\\}$\n",
    "\n",
    "$ \\{x_1, x_4\\}$\n",
    "\n",
    "$ \\{x_1, x_2, x_3\\}$\n",
    "\n",
    "$ \\{x_1, x_2, x_4\\}$\n",
    "\n",
    "$ \\{x_1, x_3, x_4\\}$\n",
    "\n",
    "$ \\{x_1, x_2, x_3, x_4\\}$\n",
    "\n",
    "Os subconjuntos possíveis **que não incluem** $x_1$ são:\n",
    "\n",
    "$ \\{ \\}$ (null model - é uma simples média do target)\n",
    "\n",
    "$ \\{x_2\\}$\n",
    "\n",
    "$ \\{x_3\\}$\n",
    "\n",
    "$ \\{x_4\\}$\n",
    "\n",
    "$ \\{x_2, x_3\\}$\n",
    "\n",
    "$ \\{x_2, x_4\\}$\n",
    "\n",
    "$ \\{x_3, x_4\\}$\n",
    "\n",
    "$ \\{x_2, x_3, x_4\\}$\n",
    "\n",
    "Note, portanto, que treinamos **16 modelos diferentes** para avaliar a importância de $x_1$\n",
    "\n",
    "> No geral, para $n$ features, temos $2 \\times 2^{n-1} = 2^n$ modelos diferentes que devem ser treinados para inspecionar a importância de cada feature, ou seja, $n \\times 2^n$ modelos no total!\n",
    "\n",
    "Portanto, fica claro que a utilização de Shapley values para a interpretação de modelos é algo **computacionalmente extremamente custoso**. \n",
    "\n",
    "É pensando nisso que o método SHAP vem à nossa salvação! :D\n",
    "\n",
    "O artigo original do SHAP está [aqui](https://arxiv.org/pdf/1705.07874.pdf) -- esse é um pouquinho mais difícil, mas também é relativamente acessível!\n",
    "\n",
    "E [neste post](https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30) há detalhes interessantes sobre o funcionamento do SHAP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interlúdio matemático (conceitual): conforme dissemos, o SHAP é um método baseado em conceitos de teoria de jogos. Nesta teoria, há dois agentes muito importantes: **o jogo** e **os jogadores**. No contexto de interpretabilidade de ML, temos:\n",
    "<br>\n",
    "- Os outputs do modelo como o jogo;\n",
    "<br><br>\n",
    "- Os jogadores como as features a serem incluídas no modelo.\n",
    "<br><br>\n",
    ">A interação entre estes agentes é quantificada justamente pelo valor de Shapley. O que o SHAP faz é quantificar quanto cada feature está contribuindo na predição do modelo e para isso ele considera todas as combinações de features mencionadas acima para determinar qual a importância de uma única feature.\n",
    "\n",
    "Acesse os links acima para detalhes! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em resumo: o Shapley calcula a importância de uma determinada feature comparando o que um modelo prediz com e sem ela, mas como a ordem em que o modelo vê as features pode impactar nas predições, o shap faz essa análise considerando todas as ordens possíveis. \n",
    "\n",
    "Considerando o dataset German Credit Risk, cada variável tem sua contribuição na predição final. Pode ser que uma pequna variação na idade traga uma predição completamente diferente, enquanto uma pequena variação na renda da pessoa não tenha um efeito tão significativo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ver, na prática, como aplicar o [SHAP](https://shap.readthedocs.io/en/latest/index.html). Para instalar a lib faça:\n",
    "\n",
    "`!pip install shap`\n",
    "\n",
    "Vamos vê-la em ação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T23:19:28.516350Z",
     "start_time": "2022-03-16T23:19:27.969663Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T23:19:53.829433Z",
     "start_time": "2022-03-16T23:19:42.026401Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Cria um objeto explainer\n",
    "explainer = shap.Explainer(gb, X_train)\n",
    "\n",
    "# Calcula o valor de SHAP para cada observação da matrix X_train.\n",
    "# Será gerado um valor de SHAP para cada feature do nosso modelo.\n",
    "shap_values = explainer(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Feature Importance: Beeswarm (Enxame de abelhas)\n",
    "Neste primeiro gráfico temos a representação de todos os valores SHAP, os quais são agrupados pelas features no eixo y. Em cada um dos grupos temos os pontos rosa que indicam como altos valores daquela feature impactam na predição, enquanto pontos em azul indicam o impacto de valores baixos daquela feature. As features são ordenadas pelos valores médios de SHAP em ordem decrescente entre as mais importantes.\n",
    "\n",
    "No eixo x temos os valores de SHAP que indicam quanto aquela observação afeta na mudança nas probabilidades de log (log-odds). Deste número podemos extrair a probabilidade de sucesso (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como interpretamos o gráfico de beeswarm do SHAP?\n",
    "\n",
    "- No eixo y temos as features, ordenadas por importância;\n",
    "\n",
    "- À direita do valor zero em X representa um aumento na probabilidade de termos o target = 1, enquanto à esquerda do zero representa uma diminuição na probabilidade de termos o target = 1 (logo um aumento no target = 0)\n",
    "\n",
    "- No eixo x temos os SHAP values -- valores positivos estão positivamente associados com o target, e vice-versa;\n",
    "\n",
    "- Cada ponto é uma observação do dataset original;\n",
    "\n",
    "- As cores estão associadas com o valor absoluto da respectiva feature pra cada observação;\n",
    "\n",
    "- As observações são empilhadas para termos noção de densidade;\n",
    "\n",
    "Como exemplo, vamos analisar a feature duration que indica o tempo total do empréstimo. Vemos que os pontos rosas, que indicam um duration maior, estão à direita do SHAP 0 e, por isso, concluímos que tem um impacto positivo no target (no caso, 1). Em outras palavras, durations maiores tem uma probabilidade maior de não pagar o empréstimo (risk). O contrário também é válido: durations menores tem um impacto negativo no target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Feature Importance: Mean SHAP\n",
    "\n",
    "Para cada feature é calculada a média dos valores absolutos de SHAP considerando todas as observações. Usamos os valores absolutos para que valores positivos e negativos não se compensem. No final, temos um gráfico parecido com o feature importance visto anteriormente.\n",
    "\n",
    "Os números à direita do gráfico representam a média do SHAP para cada feature que nada mais é do que o efeito que essa feature na predição de risco de não pagar o empréstimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Feature Importance: Waterfall\n",
    "\n",
    "A partir de agora vamos utilizar o SHAP para analisar como cada feature impacta em apenas uma observação. Vamos começar com o Waterfall (gráfico de cascata).\n",
    "\n",
    "Os gráficos em cascata nos ajudam a visualizar quanto cada feature contribuiu (positivamente ou negativamente) para aquela predição quando comparado com o modelo baseline. Eles são projetados para exibir explicações para **previsões individuais**, portanto, eles esperam uma única linha de um objeto Explanation como entrada. \n",
    "\n",
    "A parte inferior de um gráfico em cascata começa com o valor esperado da saída do modelo baseline e, em seguida, cada linha mostra como a contribuição positiva (vermelha) ou negativa (azul) de cada recurso move o valor da saída do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ler o gráfico de waterfall\n",
    "- O eixo x está em unidades de probabilidades logarítmicas (log-odds), portanto, valores negativos implicam em probabilidades inferiores a 0,5.\n",
    "- O gráfico começa na parte inferior com a probabilidade do baseline. $E[f(x)]$ representa a média do valor predito desse baseline e no caso de classificação ele é apresentado em log odds (eixo x do gráfico). Dessa forma, os valores de SHAP que vemos aqui são todos relativos a essa predição média em log odds. Lembrando que:\n",
    "$$log\\_odds = \\ln(\\frac{p}{1-p})$$\n",
    "- O gráfico mostra como a adição de cada feature muda a probabilidade de inadimplência para 1 ou 0. No fim, todas as features são consideradas, e a previsão final é mostrada no valor de $f(x)$.\n",
    "- As features em vermelho são responsáveis por elevar a probabilidade de previsão acima do valor base, ou seja. aumenta a probabilidade de inadimplência.\n",
    "- As features em azul são responsáveis por reduzir a previsão abaixo do valor base, ou seja. diminui a probabilidade de inadimplência.\n",
    "- $f(x)$ é o valor final de predição para aquela observação. Ex: o credit amount aumenta em 0.95 o log odds da predição enquanto o age reduz em 0.38. Vamos fazer os histogramas do Credit amount e do Age para visualizarmos como essas features se comportam em relação ao risco.\n",
    "\n",
    "[link](https://towardsdatascience.com/introduction-to-shap-with-python-d27edc23c454)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma do Credit amount separado pelo target\n",
    "sns.histplot(data=X_train[y_train==0], x='Credit amount', label='No risk', color='yellow', binwidth=1000, binrange=[0,17000], kde=True, stat='density')\n",
    "sns.histplot(data=X_train[y_train==1], x='Credit amount', label='Risk', binwidth=1000, binrange=[0,17000], kde=True, stat='density')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vemos que o risco de inadimplência é menor para Credit amount menor que 4000. Em que local do gráfico está a observação 0 do gŕafico de waterfall acima? Faz sentido se compararmos com o valor do SHAP para essa feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma do Age separado pelo target\n",
    "sns.histplot(data=X_train[y_train==0], x='Age', label='No risk', color='yellow', binwidth=2, binrange=[15,85], kde=True, stat='density')\n",
    "sns.histplot(data=X_train[y_train==1], x='Age', label='Risk', binwidth=2, binrange=[15,85], kde=True, stat='density')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso o risco de inadimplência é maior para idades abaixo de 30 anos e acima de 53 anos. Em que local do gráfico está a observação 0 do gŕafico de waterfall acima? Faz sentido se compararmos com o valor do SHAP para essa feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprofundamento:\n",
    "\n",
    "Agora vamos entender um pouco melhor como são calculados o $E[f(x)]$ e o $f(x)$ e ver como convertê-los em probabilidades:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retorno do SHAP para a amostra 20\n",
    "shap_values[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x), a predição da nossa amostra em log-odds, é a soma do valor do modelo baseline (E[f(x)]) com a soma das contribuições marginais de cada feature (dada por shap_values[0].values)\n",
    "$$f(x) = E[f(x)] + valores\\_SHAP$$\n",
    "$$\\ln(\\frac{p}{1-p}) = E[\\ln(\\frac{p}{1-p})] + valores\\_SHAP$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = shap_values[20].base_values\n",
    "f_x = baseline + shap_values[20].values.sum()\n",
    "f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos converter o f(x) de log odds para probabilidade e comparar com nosso valor predito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def logodds2prob(logit):\n",
    "    odds = np.exp(logit)\n",
    "    prob = odds / (1 + odds)\n",
    "    return prob\n",
    "\n",
    "print('Conversão do f(x) em probabilidade: ', logodds2prob(f_x))\n",
    "print('Valor predito: ', gb.predict_proba(X_train.iloc[[20]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Feature Importance: Barplot\n",
    "O Barplot mostra basicamente a mesma informação que o waterfall, só muda a forma.\n",
    "\n",
    "As barras em rosa representam features com impacto positivo no target e em azul impacto negativo.\n",
    "\n",
    "Os números à direita do gráfico representam a média do SHAP para cada feature que nada mais é do que o efeito que essa feature tem na predição de risco de não pagar o empréstimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Feature Importance: Forceplot\n",
    "O Forceplot mostra basicamente a mesma informação que o waterfall, só muda a forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forceplot for first observation\n",
    "shap.initjs()\n",
    "shap.plots.force(shap_values[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como interpretar o Forcebar:\n",
    "- O baseline é o threshold.\n",
    "- A direção mostra para onde cada feature está conduzindo a predição em relação ao valor base.\n",
    "- As features vermelhos estão tentando empurrar os valores de previsão acima do valor base, indicando alto risco de inadimplência\n",
    "- As features azuis estão tentando empurrar a previsão abaixo do valor base, indicando baixo risco de inadimplência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E para regressão como fica? Exercício para casa! Use o dataset abaixo e escolha um modelo de sua preferência para fazer as análises de interpretabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia e aprofundamento\n",
    "- [SHAP em modelo de regressão e outros gráficos](https://towardsdatascience.com/introduction-to-shap-with-python-d27edc23c454)\n",
    "- [Analisando interações entre features com SHAP](https://towardsdatascience.com/analysing-interactions-with-shap-8c4a2bc11c2a)\n",
    "- [SHAP: Decision Plot](https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/decision_plot.html)\n",
    "- [SHAP: Heatmap Plot](https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/heatmap.html)\n",
    "- [Advanced Uses of SHAP Values](https://www.kaggle.com/code/dansbecker/advanced-uses-of-shap-values/tutorial)\n",
    "- [SHAP](https://www.analyticsvidhya.com/blog/2022/01/build-a-trustworthy-model-with-explainable-ai/)\n",
    "- [Introduction to shap with python](https://towardsdatascience.com/introduction-to-shap-with-python-d27edc23c454)\n",
    "- [Interpreting complex models with shap values](https://medium.com/@gabrieltseng/interpreting-complex-models-with-shap-values-1c187db6ec83)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb5f626699f206ef97176a4f092b8d9f6e52ae1f84b4bb3163daf9eb25ca3519"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aula_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249.667px",
    "width": "359.667px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
